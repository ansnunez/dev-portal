<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Mitigation measures · Zilliqa Developer Portal</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="## Guard Mode"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Mitigation measures · Zilliqa Developer Portal"/><meta property="og:type" content="website"/><meta property="og:url" content="https://ansnunez.github.io/dev-portal/"/><meta property="og:description" content="## Guard Mode"/><meta property="og:image" content="https://ansnunez.github.io/dev-portal/img/docusaurus.png"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://ansnunez.github.io/dev-portal/img/docusaurus.png"/><link rel="shortcut icon" href="/dev-portal/img/favicon.png"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script src="/dev-portal/js/scrollSpy.js"></script><link rel="stylesheet" href="/dev-portal/css/main.css"/><script src="/dev-portal/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/dev-portal/en"><img class="logo" src="/dev-portal/img/zilliqa-logo_1zilliqa-logo.png" alt="Zilliqa Developer Portal"/><h2 class="headerTitleWithLogo">Zilliqa Developer Portal</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/dev-portal/docs/en/basics-intro-blockchain" target="_self">Basics</a></li><li class=""><a href="/dev-portal/docs/en/dev-started-helloworld" target="_self">Developers</a></li><li class=""><a href="/dev-portal/docs/en/mining-general-info" target="_self">Miners</a></li><li class=""><a href="/dev-portal/docs/en/staking-getting-started" target="_self">Exchanges</a></li><li class="siteNavGroupActive"><a href="/dev-portal/docs/en/contribute-buildzil" target="_self">Contributors</a></li><span><li><a id="languages-menu" href="#"><img class="languages-icon" src="/dev-portal/img/language.svg" alt="Languages icon"/>English</a><div id="languages-dropdown" class="hide"><ul id="languages-dropdown-items"><li><a href="/dev-portal/docs/zh-CN/core-mitigation-measures">中文</a></li></ul></div></li><script>
        const languagesMenuItem = document.getElementById("languages-menu");
        const languagesDropDown = document.getElementById("languages-dropdown");
        languagesMenuItem.addEventListener("click", function(event) {
          event.preventDefault();

          if (languagesDropDown.className == "hide") {
            languagesDropDown.className = "visible";
          } else {
            languagesDropDown.className = "hide";
          }
        });
      </script></span></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>Core protocol design</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle">Contribute</h3><ul class=""><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Contribution guide</h4><ul><li class="navListItem"><a class="navItem" href="/dev-portal/docs/en/contribute-buildzil">Building Zilliqa</a></li><li class="navListItem"><a class="navItem" href="/dev-portal/docs/en/contribute-guidelines">Coding and contribution guidelines</a></li><li class="navListItem"><a class="navItem" href="/dev-portal/docs/en/contribute-bug-bounty">Bug bounty program</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Core protocol design</h4><ul><li class="navListItem"><a class="navItem" href="/dev-portal/docs/en/core-node-operation">General node operation</a></li><li class="navListItem"><a class="navItem" href="/dev-portal/docs/en/core-consensus">Consensus</a></li><li class="navListItem"><a class="navItem" href="/dev-portal/docs/en/core-network">Network communication and topographies</a></li><li class="navListItem"><a class="navItem" href="/dev-portal/docs/en/core-messaging">Messaging</a></li><li class="navListItem"><a class="navItem" href="/dev-portal/docs/en/core-data">Data layer</a></li><li class="navListItem"><a class="navItem" href="/dev-portal/docs/en/core-directory-service">Directory service</a></li><li class="navListItem"><a class="navItem" href="/dev-portal/docs/en/core-shard">Shard node</a></li><li class="navListItem"><a class="navItem" href="/dev-portal/docs/en/core-lookup">Lookup</a></li><li class="navListItem"><a class="navItem" href="/dev-portal/docs/en/core-mining">Mining</a></li><li class="navListItem navListItemActive"><a class="navItem" href="/dev-portal/docs/en/core-mitigation-measures">Mitigation measures</a></li><li class="navListItem"><a class="navItem" href="/dev-portal/docs/en/core-tools">Tools</a></li></ul></div></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer docsContainer"><div class="wrapper"><div class="post"><header class="postHeader"><h1 id="__docusaurus" class="postHeaderTitle">Mitigation measures</h1></header><article><div><span><h2><a class="anchor" aria-hidden="true" id="guard-mode"></a><a href="#guard-mode" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Guard Mode</h2>
<h3><a class="anchor" aria-hidden="true" id="description"></a><a href="#description" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Description</h3>
<p>Guard mode is a special operating mode in Zilliqa. Guard mode is a safety feature that can be used at the start of the mainnet til mainnet is stable. Guard mode will ensure the following:</p>
<ul>
<li>Up to <code>n</code> (for instance, 2/3) nodes in DS committee are controlled by Zilliqa Research</li>
<li>DS leader selection, in normal scenario and view change scenario, will only be done from nodes controlled by Zilliqa Research</li>
<li>Up to <code>n</code> (for instance, 1/3) nodes across all shards are controlled by Zilliqa Research</li>
</ul>
<p><strong>Guard mode is designed to be toggleable and does not interfere with standard protocol when not in guard mode.</strong></p>
<h3><a class="anchor" aria-hidden="true" id="terminology"></a><a href="#terminology" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Terminology</h3>
<ul>
<li>DS guard - DS node controlled by Zilliqa Research</li>
<li>Shard guard - Shard node controlled by Zilliqa Research</li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="operation"></a><a href="#operation" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Operation</h3>
<ol>
<li>To enable guard mode, set <code>GUARD_MODE</code> to <code>true</code> in <code>constants.xml</code></li>
<li>Add <code>n</code> DS guard public keys to <code>ds_guard.DSPUBKEY</code> in <code>constants.xml</code></li>
<li>Add <code>n</code> shard guard public keys to <code>shard_guard.SHARDPUBKEY</code> in <code>constants.xml</code></li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="design-of-ds-guard-and-non-ds-guard-nodes"></a><a href="#design-of-ds-guard-and-non-ds-guard-nodes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Design of DS guard and non-DS guard nodes</h3>
<h4><a class="anchor" aria-hidden="true" id="normal-operation"></a><a href="#normal-operation" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Normal operation</h4>
<p>DS guard is designed to be statically placed in the DS committee. The first <code>n</code> nodes in the DS committee will be designated as DS guards. These do not change or shift during each DS consensus or view change while in guard mode.</p>
<table>
<thead>
<tr><th>1...n = DS guards (controlled by Zilliqa Research)</th><th>n+1...m = non-guard nodes</th></tr>
</thead>
<tbody>
</tbody>
</table>
<p>DS Leader is selected from DS guards, by doing <code>mod n</code> rather than <code>mod m</code>.</p>
<p>Non-guard node joins the DS committee via PoW (according to DS difficulty). It will be emplaced starting from <code>n+1</code> index. As per usual operation, the last few DS nodes (non-guards) will be ejected from the DS committee.</p>
<blockquote>
<p>Note: The DS reputation feature (starting v5.0.0) also impacts DS committee member placement. Please refer to both DS MIMO and DS Reputation documents for more information on how DS committee membership is managed.</p>
</blockquote>
<h4><a class="anchor" aria-hidden="true" id="view-change-operation"></a><a href="#view-change-operation" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>View change operation</h4>
<p>When there is a view change, it is likely that a DS guard (leader) is faulty or the network failed to agree with what the DS guard (leader) proposed. In such a case, view change will happen. View change candidate leader will be selected from <code>1...n</code> DS guards by doing <code>mod n</code> rather than <code>mod m</code>.</p>
<p>Upon view change completion, there is no shifting of DS guard nodes. The DS guards stay in place. Shard nodes who receive the VC block will also not adjust the DS committee.</p>
<p>The DS committee updates <code>m_consensusLeaderID</code> to the new leader and the protocol resumes.</p>
<h4><a class="anchor" aria-hidden="true" id="rebalancing-for-shards"></a><a href="#rebalancing-for-shards" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Rebalancing for shards</h4>
<p>In the event that there is a reduction in the number of shards, we ensure that the remaining shards will not be entirely made up of guards. To do this, we trim the overall number of shard guards to 2/3 of the expected population (e.g., 1200 out of 1800), and then complete the count with non-shard guards. In the case where there are insufficient non-guard nodes, shard guard nodes will fill up the remaining slots.</p>
<p>Keywords to look for in the logs:</p>
<pre><code class="hljs css language-console">DS leader:
trimmedGuardCount: [some value] trimmedNonGuardCount: [some value] Total number of accepted soln: [some value]

Example:
trimmedGuardCount: 80 trimmedNonGuardCount: 40 Total number of accepted soln: 120
</code></pre>
<h4><a class="anchor" aria-hidden="true" id="reducing-shard-guards"></a><a href="#reducing-shard-guards" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Reducing shard guards</h4>
<p>Reference: <a href="https://github.com/Zilliqa/Zilliqa/pull/1508">PR 1508</a></p>
<blockquote>
<p>Note: This section may need to be revised once shard guard reduction is planned for the mainnet.</p>
</blockquote>
<p>When we need to reduce shard nodes, we will need to adjust the following constants which dictate the min % of shard guards per shard.</p>
<pre><code class="hljs css language-console">&lt;SHARD_GUARD_TOL&gt;0.334&lt;/SHARD_GUARD_TOL&gt;
</code></pre>
<p>The key idea to remove shard guard from shard is to remove <code>&lt;SHARDPUBKEY&gt;</code> from <code>constants.xml</code> during the upgrading.</p>
<p>For recovery and upgrading approach, you may follow the following testnet steps to conduct testing. The current steps remove 80 shard nodes (shard guards included).</p>
<pre><code class="hljs css language-console">Baseline testnet (eg. current latest release).
Bootstrap one or skip this if you are getting from persistence from mainnet

./bootstrap.py -c &lt;latest release commit&gt; -n 200 -d 50 --guard 34/102 -l 1 --host-network true --gentxn false --lookup-multiplier true --default-genesis 5 --extra-genesis 5 --port 33133 &lt;original testnet name&gt;

Upload persistence
./testnet.sh upload dev.k8s.z7a.xyz &lt;original testnet name&gt;

Recover and upgrade to a smaller testnet
./bootstrap.py -c &lt;new commit&gt; -n 120 -d 50 --guard 34/51 -l 1 --host-network true --gentxn false --lookup-multiplier true --default-genesis 5 --extra-genesis 5 --port 33133 --recover-from-testnet jh3420 --recover-from-cluster dev.k8s.z7a.xyz &lt;new testnet name&gt;
</code></pre>
<h4><a class="anchor" aria-hidden="true" id="best-effort-approach-for-electing-shard-guard-as-shard-leader"></a><a href="#best-effort-approach-for-electing-shard-guard-as-shard-leader" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Best effort approach for electing shard guard as shard leader</h4>
<p>Reference: <a href="https://github.com/Zilliqa/Zilliqa/pull/1513">PR 1513</a></p>
<p>A best effort approach for selecting shard guard as shard leader was introduced in the PR. Recall that whether or not we are in guard mode, the calculation of new shard leader is:</p>
<pre><code class="hljs css language-console">Leader index = last block hash % shard size
</code></pre>
<p>The new calculation is as follows:</p>
<pre><code class="hljs css language-console">Leader index = last block hash % shard size

while leader is not shard guard (iterate up to n times)
Hash = sha2(last block hash)
Leader index = Hash % shard size

n is defined in constant SHARD_LEADER_SELECT_TOL
</code></pre>
<h4><a class="anchor" aria-hidden="true" id="runtime-validation"></a><a href="#runtime-validation" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Runtime validation</h4>
<p>Guard mode is designed to run when the following assumption holds:</p>
<ul>
<li>Number of new DS node injected into shard &gt;= number of allowed non-guard shard nodes</li>
</ul>
<p>Using a simple local run as an example:</p>
<ul>
<li>Number of nodes: 20</li>
<li>DS nodes: 10</li>
<li>Shard size: 5</li>
<li>DS MIMO: 2</li>
</ul>
<table>
<thead>
<tr><th>10 DS Node (8 guards)</th><th>Shard 1: 5 Nodes (4 guards)</th><th>Shard 2: 5 Nodes (4 guards)</th></tr>
</thead>
<tbody>
</tbody>
</table>
<p>In such a case, when the network is reduced from 2 shards to 1 shard (due to some reason), the injection phase will inject more nodes than the shard limit. There is no good solution around it. Hence, <code>ValidateRunTimeEnvironment()</code> checks for such a condition and logs fatal if it happens.</p>
<table>
<thead>
<tr><th>10 DS Node (8 guards)</th><th>Shard 1: 6 Nodes (4 guards)</th><th>No longer exists</th></tr>
</thead>
<tbody>
</tbody>
</table>
<h3><a class="anchor" aria-hidden="true" id="changing-network-information-of-ds-guard-node"></a><a href="#changing-network-information-of-ds-guard-node" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Changing network information of DS guard node</h3>
<h4><a class="anchor" aria-hidden="true" id="purpose"></a><a href="#purpose" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Purpose</h4>
<p>Nodes (or, specifically, docker containers) can be terminated due to software or hardware reasons. Under normal operation without guard mode, faulty DS node(s) can be gracefully kicked out of the DS committee using regular shifting and view change if necessary. However, in guard mode, DS guards do not shift and stay in the DS committee indefinitely. As such, we can possibly lose a node forever as Kubernetes does not support static IP addressing.</p>
<p>As such, we have devised a simple protocol for the DS guard to rejoin and update the network about its new information.</p>
<h4><a class="anchor" aria-hidden="true" id="updating-mechanism"></a><a href="#updating-mechanism" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Updating mechanism</h4>
<ol>
<li>DS guard relaunches in a new pod</li>
<li>DS guard enters the DS guard rejoin stage and syncs with lookup</li>
<li>DS guard successfully enters <code>FinishRejoinAsDS()</code></li>
<li>As part of the finish rejoin process, DS guard broadcasts its new network information and other relevant information to the lookup and gossips to DS committee (pubkey, network info and timestamp)</li>
<li>DS committee and lookup update their view of the DS committee</li>
<li>Lookup stores the updated information</li>
<li>At the next vacuous epoch, all shard nodes query the lookup for any new DS guard network update info, and set a flag to indicate that they are waiting for the new network information of DS guard</li>
<li>Lookup will not respond if there is no new information</li>
<li>Otherwise, lookup sends to requesting shard node the new DS guard network information. The lookup also signs the message.</li>
<li>Requesting shard node verifies the signature and proceeds to update its view of the DS committee.</li>
</ol>
<h4><a class="anchor" aria-hidden="true" id="testing-procedures"></a><a href="#testing-procedures" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Testing procedures</h4>
<ol>
<li><p>Run 20 nodes testnet with guard mode enabled</p></li>
<li><p>Kill 2nd DS guard node</p>
<ul>
<li>netstat -antp | less</li>
<li>Look for port 4002</li>
<li>Get the process id</li>
<li>kill -9 [pid]</li>
</ul></li>
<li><p>Relaunch DS guard node 2 using <code>./tests/Node/test_node_rejoindsguardnode2</code></p></li>
<li><p>Check that DS committee, lookup and shard nodes are aware of the DS guard's updated network information</p>
<ul>
<li>DS committee:</li>
</ul>
<pre><code class="hljs css language-console">[update ds guard] DS guard to be updated is at index
[indexOfDSGuard] [old network info] [new network info]
</code></pre>
<ul>
<li>Shards:</li>
</ul>
<pre><code class="hljs css language-console">[update ds guard][pubkey]new network info is [network info]
</code></pre>
<ul>
<li>Lookup:
<ul>
<li><p>Received network info:</p>
<pre><code class="hljs css language-console">[update ds guard] DS guard to be updated is at index
[indexOfDSGuard] [old network info] [new network info]
</code></pre></li>
<li><p>Add to in-memory data structure:</p>
<pre><code class="hljs css language-console">[update ds guard] No existing record found for dsEpochNumber [ds epoch number]. Adding a new record

Or

[update ds guard] Adding new record for dsEpochNumber [ds epoch number]
</code></pre></li>
<li><p>Send to shard node:</p>
<pre><code class="hljs css language-console">[update ds guard] Sending guard node update info to [requesting node]
</code></pre></li>
</ul></li>
</ul></li>
</ol>
<h4><a class="anchor" aria-hidden="true" id="sequence-diagram"></a><a href="#sequence-diagram" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Sequence Diagram</h4>
<p><img src="../assets/core/features/guard-mode/image01.png" alt="image01"></p>
<h3><a class="anchor" aria-hidden="true" id="design-of-shard-guard-and-non-shard-guard-nodes"></a><a href="#design-of-shard-guard-and-non-shard-guard-nodes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Design of shard guard and non-shard guard nodes</h3>
<p>Shard guard is designed to ensure that across all shards there are sufficient Zilliqa-controlled nodes. These nodes are special as</p>
<ul>
<li>They do PoW with difficulty 1</li>
<li>Their PoW submissions are given priority by DS committee over normal shard nodes' submissions</li>
<li>They do not join DS committee</li>
</ul>
<p>As per the Zilliqa protocol, shard nodes (guard and non-guard) perform PoW. A non-guard node may perform up to 2 rounds of PoW (one for DS and one for shard). <strong>However, a shard guard only performs PoW to enter shard.</strong></p>
<p>After the PoW window is over, the DS committee will begin to compose the sharding structure. The DS leader, as per current protocol, will trim the sharding structure such that each shard has exactly <code>COMM_SIZE</code> number of shard nodes. During the trimming, shard guards are given priority, and non-shard guard nodes are trimmed from the structure first. With the trimmed list, the DS leader will then randomly assign each node (shard guard and non-shard guard) to its respective shard.</p>
<p>Inline code comments:</p>
<pre><code class="hljs css language-console">If total num of shard nodes to be trim, ensure shard guards do not get
 trimmed. To do it, a new map  will be created to include all shard
 guards and a subset of normal shard nods
Steps:
 1. Maintain a map that called "FilteredPoWOrderSorter". It will
 eventually contains Shard guards + subset of normal nodes
 2. Maintain a shadow copy of "PoWOrderSorter" called
 "ShadowPoWOrderSorter". It is to track non-guards node.
 3. Add shard guards to "FilteredPoWOrderSorter" and remove it from
 "ShadowPoWOrderSorter"
 4. If there are still slots left, obtained remaining normal shard node
 from "ShadowPoWOrderSorter". Use it to populate
 "FilteredPoWOrderSorter"
 5. Finally, sort "FilteredPoWOrderSorter" and stored result in
 "PoWOrderSorter"
</code></pre>
<h3><a class="anchor" aria-hidden="true" id="running-in-local-test-mode"></a><a href="#running-in-local-test-mode" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Running in local test mode</h3>
<p>Local scripts have been retrofitted and DS/shard guard node key pairs have been pre-generated in the python local script. To run guard mode, use <code>tests/Node/pre_run_guard.sh</code> instead of the regular <code>pre_run</code> script.</p>
<pre><code class="hljs css language-console">cd build &amp;&amp; tests/Node/pre_run_guard.sh &amp;&amp; ./tests/Node/test_node_lookup.sh &amp;&amp; ./tests/Node/test_node_simple.sh
</code></pre>
<h3><a class="anchor" aria-hidden="true" id="test-scenarios"></a><a href="#test-scenarios" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Test scenarios</h3>
<ol>
<li>Normal operation with guard mode
<ul>
<li>Build as per normal</li>
<li>Enable guard mode</li>
</ul></li>
<li>Guard mode with view change at DS block consensus
<ul>
<li>Build with VC1</li>
<li>Enable guard mode</li>
</ul></li>
<li>Guard mode with view change at final block consensus
<ul>
<li>Build with VC3</li>
<li>Enable guard mode</li>
</ul></li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="validating-the-results-via-sampling"></a><a href="#validating-the-results-via-sampling" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Validating the results via sampling</h3>
<ol>
<li>Check a DS guard node (e.g., node 1) to see whether or not it stays in DS committee indefinitely with no shifting</li>
<li>Check a DS guard node to ensure DS leader is always among the DS guard nodes</li>
<li>Check a shard guard node to ensure it never joins the DS committee</li>
<li>Check a non-shard guard node to ensure it has the chance to join the DS committee</li>
<li>Check view change in guard mode doesn’t shift the DS committee</li>
<li>Check lookup for any abnormal behavior</li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="future-todos"></a><a href="#future-todos" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Future todos</h3>
<ol>
<li>How to gracefully transit out of guard mode? (<a href="https://github.com/Zilliqa/Issues/issues/336">Issue 336</a>)</li>
</ol>
<h2><a class="anchor" aria-hidden="true" id="rejoin-mechanism"></a><a href="#rejoin-mechanism" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Rejoin Mechanism</h2>
<p>This document will walk through joining and rejoining of different types of nodes.</p>
<h3><a class="anchor" aria-hidden="true" id="new-node-joining---existing-shard-node-joiningminer-node-was-relaunchedrestarted-via-launcher-script"></a><a href="#new-node-joining---existing-shard-node-joiningminer-node-was-relaunchedrestarted-via-launcher-script" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>New node joining  / Existing shard node joining(Miner node was relaunched/restarted via launcher script)</h3>
<ol>
<li>launch_docker.sh / launch.sh / start.sh download persistence from AWS S3 incremental db using <code>download_incr_db.py</code>. It skips downloading microbBlocks and txBodies. More details of download_incr_db.py can be found <a href="incremental-db.md">here</a>.</li>
<li>Above launcher script later starts the zilliqa process with <code>syncType = NEW_SYNC</code>.</li>
<li>Zilliqa process retrieves Persistence Storage from dowloaded DB in (1).</li>
<li>It regenerates the current state using base state and state-deltas already fetched from incremental db.</li>
<li>syncType is not No_SYNC. so it blocks some messages that will be received as a healthy normal node.</li>
<li>It starts synchronization with <code>Node::StartSynchronization</code>.</li>
</ol>
<h4><a class="anchor" aria-hidden="true" id="nodestartsynchronization"></a><a href="#nodestartsynchronization" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><code>Node::StartSynchronization</code></h4>
<ol>
<li><p>Send request to upper seeds (level2lookup 10- 14) so as to remove node IP from their relaxed blacklist, if any.</p></li>
<li><p>While Loop until syncType becomes NO_SYNC:</p></li>
<li><p>Fetch Latest DSBlocks and Latest TxBlocks from a random upper seed.</p></li>
<li><p>On receiving new TxBlock, fetch the corresponding state-deltas and calculate current state. Check whether it is a vacuous block, if so, after calculating state will move the state update to disk.</p></li>
<li><p>If not vacuous epoch,
a) Fetch the latest Sharding Structure from a random upper seed and identify if already part of any shard.
b) If it's not part of any shard, then it's indeed a new miner then go back to step (4).
c) <strong>Otherwise, already part of one of shard</strong>. Set my shard members and shardId. Set <code>sycType = NO_SYNC</code> and send request to shard peers to remove IP from their relaxed blacklist.</p>
<hr>
<p><strong>NOTE:</strong>
If connection to node fails with error <code>EHOSTDOWN</code> or <code>ECONNREFUSED</code>, it's blacklisted in <code>relaxed</code> category. Otherwise in strict category.</p>
<hr>
<p>d) Start next Tx epoch where it initializes node variables like m_consensusID, m_consensusLeaderID, etc. Identify being BACKUP or leader, initializes Rumor Manager and starts with MicroBlockConsensus.
The normal node now successfully joined the network as Shard Node.</p></li>
<li><p>If vacuous epoch, fetch Latest DS Committee Info and send request to a random upper seed to let him know when to start pow.</p></li>
<li><p>On receiving notification message from seed, start Init Mining and submit PoW.</p></li>
<li><p>If received DSBlock within timeout and finds himself in sharding information, change <code>syncType = NO_SYNC</code>. Stop blocking messages. <strong>The normal node now successfully joined the network as Shard Node</strong> .</p></li>
<li><p>If timedout,
a) Try to fetch latest DSBlock from random seed. If successfully got new DSBlock means lost pow this time.
It will continue syncing until next vacuous epoch as above by invoking <code>Node::StartSynchronization</code>.
b) If failed to get new DSBlock, set <code>syncType = NORMAL_SYNC</code> and triggers <code>Node::RejoinAsNormal</code>.</p></li>
</ol>
<h4><a class="anchor" aria-hidden="true" id="noderejoinasnormal"></a><a href="#noderejoinasnormal" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><code>Node::RejoinAsNormal</code></h4>
<ol>
<li>Set <code>SyncType = NORMAL_SYNC</code>.</li>
<li>Download Persistence from S3 incremental DB.</li>
<li>Retrieves Persistence Storage from dowloaded DB in step (2).</li>
<li>It regenerates the current state using base state and state-deltas already fetched from incremental db.</li>
<li>syncType is not No_SYNC. so it blocks some messages that will be received as a healthy normal node.</li>
<li>It starts synchronization with <code>Node::StartSynchronization</code>.</li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="shard-node---daemon-starts-the-killed-zilliqa-process-applicable-only-for-zilliqa-nodes"></a><a href="#shard-node---daemon-starts-the-killed-zilliqa-process-applicable-only-for-zilliqa-nodes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Shard node - Daemon starts the killed zilliqa process (applicable only for zilliqa nodes)</h3>
<ol>
<li>Daemon starts the process with syncType in previous run. <code>i.e. SyncType = 5</code></li>
<li>Its as good as recovery of any node from exising local persistence here onwards. Refer <a href="recovery.md">Recovery</a>.</li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="existing-ds-node-joining--ds-node-was-relaunchedrestarted-via-launcher-script"></a><a href="#existing-ds-node-joining--ds-node-was-relaunchedrestarted-via-launcher-script" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Existing DS node joining ( DS node was relaunched/restarted via launcher script)</h3>
<ol>
<li>launch_docker.sh / launch.sh / start.sh download persistence from AWS S3 incremental db using <code>download_incr_db.py</code>. It skips downloading microBlocks and txBodies. More details of download_incr_db.py can be found here.</li>
<li>Above launcher script later starts the zilliqa process with <code>syncType = NEW_SYNC</code>.</li>
<li>Zilliqa process retrieves Persistence Storage from dowloaded DB in step (1).</li>
<li>syncType is not <code>NO_SYNC</code>. so it blocks some messages that will be received as a healthy normal node.</li>
<li>It regenerates the current state using base state and state-deltas already fetched from incremental db.</li>
<li>Check if node is part of current ds committee, If so
a) Save coin base for final block and all microblocks, from last DS epoch to current TX epoch.
b) Send request to upper seeds (level2lookup 10- 14) so as to remove node IP from their relaxed blacklist, if any.
c) If any of the coinbase is missing for any epoch or any shard, request cosigs for them from a random upper seed.
d) Set <code>syncType = DS_SYNC</code>.</li>
<li>It starts synchronization with <code>DirectoryService::StartSynchronization</code>.</li>
</ol>
<h4><a class="anchor" aria-hidden="true" id="directoryservicestartsynchronization"></a><a href="#directoryservicestartsynchronization" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><code>DirectoryService::StartSynchronization</code></h4>
<ol>
<li>Send request to upper seeds (level2lookup 10- 14) so as to remove node IP from their relaxed blacklist, if any.</li>
<li>While Loop until SyncType becomes NO_SYNC:</li>
<li>Fetch Latest DSBlocks and Latest TxBlocks from a random upper seed.</li>
<li>On receiving new TxBlock, fetch the corresponding statedeltas and calculate current state. Check whether it is a vacuous block, if so, after calculating state will move the state update to disk.</li>
<li>If node is dsguard and if rejoining was triggered because the pod/instance was deleted i.e. <code>m_ds.m_dsguardPodDelete = true</code>(Refer <a href="recovery.md##DSGuardNodePod/InstanceDeletion">DSGuard Pod Deletion</a>), then invokes <code>FinishRejoinAsDS</code> only if its vacous epoch.</li>
<li>Otherwise, trigger <code>FinishRejoinAsDS</code> immediately.</li>
</ol>
<h4><a class="anchor" aria-hidden="true" id="directoryservicefinishrejoinasds"></a><a href="#directoryservicefinishrejoinasds" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><code>DirectoryService::FinishRejoinAsDS</code></h4>
<ol>
<li>Recheck if node is still part of ds committee. If not triggers <code>RejoinAsNormal</code>.</li>
<li>If node is awaiting sending new IP to network i.e. <code>m_ds.m_awaitingToSubmitNetworkInfoUpdate = true</code>(Refer <a href="recovery.md##DSGuardNodePod/InstanceDeletion">DSGuard Pod Deletion</a>), send new IP to the network.</li>
<li>If current epoch is already first tx epoch of new ds epoch, fetch the sharding structure again.</li>
<li>If not vacuous epoch, start next Tx epoch where it initializes node variables like m_consensusID, m_consensusLeaderID, etc. Identify being BACKUP or leader, initializes Rumor Manager and starts with state <code>MICROBLOCK_SUBMISSION</code>.</li>
<li>If vacuous epoch, start new ds epoch and starts with state <code>POW_SUBMISSION</code>.</li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="ds-node---when-vc-precheck-fails"></a><a href="#ds-node---when-vc-precheck-fails" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>DS node - when VC Precheck fails</h3>
<p>VC Precheck fails if next tx block or ds block got mined, but node failed to reach consensus for that block.
After which is triggers <code>DirectoryService::RejoinAsDS</code>.</p>
<h4><a class="anchor" aria-hidden="true" id="directoryservicerejoinasds"></a><a href="#directoryservicerejoinasds" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><code>DirectoryService::RejoinAsDS</code></h4>
<ol>
<li>Set <code>SyncType = DS_SYNC</code>.</li>
<li>Download Persistence from S3 incremental DB.</li>
<li>It retrieves Persistence Storage from dowloaded DB in step (2).</li>
<li>It starts synchronization with <code>DirectoryService::StartSynchronization</code>.</li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="ds-node---daemon-starts-the-killed-zilliqa-process-applicable-only-for-zilliqa-nodes"></a><a href="#ds-node---daemon-starts-the-killed-zilliqa-process-applicable-only-for-zilliqa-nodes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>DS node - Daemon starts the killed zilliqa process (applicable only for zilliqa nodes)</h3>
<ol>
<li>Daemon starts the process with syncType in previous run. <code>i.e. SyncType = 5</code></li>
<li>Its as good as recovery of any node from existing local persistence here onwards. Refer <a href="recovery.md">Recovery</a></li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="new-seed-node-joining"></a><a href="#new-seed-node-joining" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>New Seed Node joining</h3>
<ol>
<li>launch_docker.sh / launch.sh / start.sh download persistence from AWS S3 incremental db using <code>download_incr_db.py</code>. More details of download_incr_db.py can be found here <a href="incremental-db.md">here</a>.</li>
<li>Above launcher script later starts the zilliqa process with <code>syncType = NEW_LOOKUP_SYNC</code>.</li>
<li>Zilliqa process retrieves Persistence Storage from dowloaded DB in step (1).</li>
<li>It regenerates the current state using base state and statedeltas already fetched from incremental db.</li>
<li>SyncType is not <code>NO_SYNC</code>. so it blocks some messages that will be received as a healthy seed node.</li>
<li>It starts syncronization with <code>Lookup::InitSync</code>.</li>
</ol>
<h4><a class="anchor" aria-hidden="true" id="lookupinitsync"></a><a href="#lookupinitsync" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><code>Lookup::InitSync</code></h4>
<ol>
<li>While Loop until SyncType becomes <code>NO_SYNC</code>:</li>
<li>Fetch Latest DSBlocks and Latest TxBlocks from a random upper seed.</li>
<li>On receiving new TxBlock, fetch the corresponding statedeltas and calculate current state. Check whether it is a vacuous block, if so, after calculating state will move the state update to disk.</li>
<li>Fetch UnavailableMicroBlockHashes for the newly fetched txBlocks from random lookup nodes. And also check for any missing mbs from last N txBlocks and fetch them from random lookup nodes, if any. (See <code>Lookup::CommitTxBlocks</code>)</li>
<li>Fetch latest DSInfo and Set <code>syncType = NO_SYNC</code>, then seed is ready again.</li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="seed-node-rejoining-also-applicable-for-newlookup--level2lookup-nodes"></a><a href="#seed-node-rejoining-also-applicable-for-newlookup--level2lookup-nodes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Seed Node Rejoining (Also applicable for newlookup / level2lookup nodes)</h3>
<p>Seed nodes might miss receiving any final block or ds block from multiplier (See more at ), in which case it triggers <code>RejoinAsNewlookup</code> to rejoin.</p>
<ol>
<li>Set <code>syncType = NEW_LOOKUP_SYNC</code>.</li>
<li>If the number of missing final block are over NUM_FINAL_BLOCK_PER_POW (extreme bound), rejoin from S3 incremental db will be used. <code>i.e. RejoinAsNewlookup(fromLookup = false)</code></li>
<li>Otherwise, rejoin by fetching missing final blocks from random lookup nodes. <code>i.e. RejoinAsNewlookup(fromLookup = true)</code></li>
</ol>
<h4><a class="anchor" aria-hidden="true" id="lookuprejoinasnewlookup"></a><a href="#lookuprejoinasnewlookup" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><code>Lookup::RejoinAsNewlookup</code></h4>
<p>If <code>fromLookup = true</code>:</p>
<ol>
<li>Invoke <code>Lookup::StartSynchronization</code></li>
</ol>
<p>If <code>fromLookup = false</code>:</p>
<ol>
<li>Download Persistence from S3 incremental DB.</li>
<li>It retrieves Persistence Storage from dowloaded DB in step (1).</li>
<li>It starts syncronization with <code>Lookup::InitSync</code>.</li>
</ol>
<h4><a class="anchor" aria-hidden="true" id="lookupstartsynchronization"></a><a href="#lookupstartsynchronization" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><code>Lookup::StartSynchronization</code></h4>
<ol>
<li>It fetches latest TxBlock and DSBlock from a random upper seed.</li>
<li>On receiving new TxBlock, fetch the corresponding statedeltas and calculate current state. Check whether it is a vacuous block, if so, after calculating state will move the state update to disk.</li>
<li>Fetch UnavailableMicroBlockHashes for the newly fetched txBlocks from random lookup nodes. And also check for any missing mbs from last N txBlocks and fetch them from random lookup nodes, if any. (See <code>Lookup::CommitTxBlocks</code>)</li>
<li>Fetch latest DSInfo and Set <code>syncType = NO_SYNC</code>, then seed/lookup is ready again.</li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="lookup-node-rejoining"></a><a href="#lookup-node-rejoining" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Lookup Node Rejoining</h3>
<p>Lookup nodes might miss receiving any final block or ds block from network, in which case it triggers <code>RejoinAsLookup</code> to rejoin.</p>
<h4><a class="anchor" aria-hidden="true" id="lookuprejoinaslookup"></a><a href="#lookuprejoinaslookup" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><code>Lookup::RejoinAsLookup</code></h4>
<ol>
<li>Invoke <code>Lookup::StartSynchronization</code>.</li>
</ol>
<h2><a class="anchor" aria-hidden="true" id="recovery-mechanism"></a><a href="#recovery-mechanism" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Recovery Mechanism</h2>
<p><code>Recovery</code> enables zilliqa controlled nodes to be recovered if they go out of sync with network.
Recovery mechanism can be used with different nodes of types - dsguard, shard guard, other normal nodes,
lookup, newlookup and level2lookup.</p>
<p><strong>Procedure :</strong></p>
<pre><code class="hljs css language-Usage: ./testnet.sh recover TYPE &quot;INDEX1 INDEX2 INDEX3 ...&quot; [ -u UPLOAD_TYPE UPLOAD_INDEX ]"><span class="hljs-built_in">
TYPE </span>could be normal, lookup, new, newlookup, level2lookup, dsguard
INDEX needs be a valid integer
UPLOAD_TYPE could be normal, lookup, new, newlookup, level2lookup, dsguard <span class="hljs-keyword">to</span> indicate the upload node<span class="hljs-built_in"> type
</span>UPLOAD_INDEX needs be a valid integer, <span class="hljs-keyword">to</span> indicate <span class="hljs-keyword">to</span> upload node index

</code></pre>
<p>Above script will download persistence from the specified <code>UPLOAD_TYPE</code> node and restart the zilliqa process using daemon (already running in container) with <code>syncType = RECOVERY_ALL_SYNC</code>.</p>
<p>Refer <a href="https://github.com/Zilliqa/dev-docs/blob/master/devops/mainnet-maintenance.md#how-to-recover-a-node">how to recover</a> for details.</p>
<p>Based on the type of node being recovered and its existing state in current network, it will be recovered as  detailed out below.</p>
<h3><a class="anchor" aria-hidden="true" id="ds-guard-node-recovery"></a><a href="#ds-guard-node-recovery" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>DS Guard Node Recovery</h3>
<ol>
<li>Kills Zilliqa process, and suspend the new process re-launching.</li>
<li>Testnet script downloads Persistence Storage.</li>
<li>Resumes to launch Zilliqa process with <code>syncType 5</code> i.e. <code>RECOVERY_ALL_SYNC</code></li>
<li>Zilliqa process retrieves Persistence Storage downloaded earlier by testnet script in step (2).</li>
<li>syncType is not <code>NO_SYNC</code>. So it blocks some messages that will be received as a healthy node.</li>
<li>Checks if node is part of current ds committee, (which will always be the case for dsguards)
a) Save coin base in memory (not saved to persistence) for final block and all microblocks, from last DS epoch to current TX epoch .
b) Send request to upper seeds <code>level2lookup 10- 14</code> to remove node IP from their relaxed blacklist, if any.
c) If any of the coinbase is missing for any epoch or any shard, request cosigs for them from a random upper seed.
d) Set <code>m_shardID</code> and <code>m_consensusMyID</code>.</li>
<li>Invokes <code>WakeupAtTxEpoch</code> which will start with <code>FinalBlockConsensus</code>.</li>
</ol>
<p>There are two possibilities hereafter:</p>
<ul>
<li>Start consensus on next block successfully and rejoined.</li>
<li>We missed new final block during recovery process in which case it will go for VC Precheck failure followed by <strong>triggering of <code>RejoinAsDS</code></strong>. Refer <a href="join-rejoin.md###`DirectoryService::RejoinAsDS`">Rejoin</a></li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="ds-guard-node-podinstance-deletion"></a><a href="#ds-guard-node-podinstance-deletion" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>DS Guard Node Pod/Instance Deletion</h3>
<ol>
<li>On instance or Pod deletion of dsguard, new pod is assigned to that dsguard and zilliqa process is launced with <code>syncType = GUARD_DS_SYNC</code>.</li>
<li>Set <code>m_ds.m_awaitingToSubmitNetworkInfoUpdate = true</code>.</li>
<li>Set <code>m_ds.m_dsguardPodDelete = true</code>.</li>
<li>Triggers <code>DirectoryService::RejoinAsDS</code>.Refer <a href="join-rejoin.md###`DirectoryService::RejoinAsDS`">Rejoin</a></li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="shard-guard-node-recovery"></a><a href="#shard-guard-node-recovery" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Shard Guard Node Recovery</h3>
<ol>
<li>Kills Zilliqa process, and suspend the new process re-launching.</li>
<li>Testnet script downloads Persistence Storage.</li>
<li>Resumes to launch Zilliqa process with <code>syncType 5</code> i.e. <code>RECOVERY_ALL_SYNC</code></li>
<li>Zilliqa process retrieves Persistence Storage downloaded earlier by testnet script in step (2).</li>
<li>syncType is not <code>NO_SYNC</code>. So it blocks some messages that will be received as a healthy node.</li>
<li>Checks if node is part of sharding structure,
a) Set <code>m_shardID</code> and <code>m_consensusMyID</code>.</li>
<li>Invokes <code>WakeupAtTxEpoch</code> which will start with state on <code>WAITING_FINALBLOCK</code>.</li>
<li>Send request to upper seeds and his peers to remove node IP from their relaxed blacklist, if any.</li>
</ol>
<p>There are two possibilities hereafter:</p>
<ul>
<li>Receives next final block and joined back.</li>
<li>We missed new final block during recovery process in which case <strong>it will trigger <code>RejoinAsNormal</code></strong>. Refer <a href="join-rejoin.md###`Node::RejoinAsNormal`">Rejoin</a></li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="shard-guard-node-podinstance-deletion"></a><a href="#shard-guard-node-podinstance-deletion" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Shard Guard Node Pod/Instance Deletion</h3>
<ol>
<li>On instance or Pod deletion of dsguard, new pod is assigned to that dsguard and zilliqa process is launced with <code>syncType = RECOVER_ALL_SYNC</code>.</li>
<li>Node don't receive any messages from peers because of IP change and is stuck.</li>
<li>We can recover such node in next ds epoch, after which it will not be part of any shard and will trigger <code>RejoinAsNormal</code>**. Refer <a href="join-rejoin.md###`Node::RejoinAsNormal`">Rejoin</a></li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="other-node-not-part-of-ds-committe-or-any-shard"></a><a href="#other-node-not-part-of-ds-committe-or-any-shard" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Other Node (Not part of ds committe or any shard)</h3>
<ol>
<li>Kills Zilliqa process, and suspend the new process re-launching.</li>
<li>Testnet script downloads Persistence Storage.</li>
<li>Resumes to launch Zilliqa process with <code>syncType 5</code> i.e. <code>RECOVERY_ALL_SYNC</code></li>
<li>Zilliqa process retrieves Persistence Storage downloaded earlier by testnet script in step (2).</li>
<li>syncType is not <code>NO_SYNC</code>. So it blocks some messages that will be received as a healthy node.</li>
<li>If node is not part of sharding structure or current ds committee, <strong>It triggers <code>RejoinAsNormal</code></strong>. Refer <a href="join-rejoin.md###`Node::RejoinAsNormal`">Rejoin</a></li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="newlookup--level2lookup-node-recovery"></a><a href="#newlookup--level2lookup-node-recovery" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>NewLookup / Level2Lookup Node Recovery</h3>
<ol>
<li>Kills Zilliqa process, and suspend the new process re-launching.</li>
<li>Testnet script downloads Persistence Storage.</li>
<li>Resumes to launch Zilliqa process with <code>syncType 5</code> i.e. <code>RECOVERY_ALL_SYNC</code></li>
<li>Zilliqa process retrieves Persistence Storage downloaded earlier by testnet script in step (2).</li>
<li>syncType is not <code>NO_SYNC</code>. So it blocks some messages that will be received as a healthy node.</li>
<li>Invokes <code>WakeupAtTxEpoch</code> which will start with state on <code>WAITING_FINALBLOCK</code>.</li>
</ol>
<p>There are two possibilities hereafter:</p>
<ul>
<li>Receives next final block and joined back.</li>
<li>We missed new final block during recovery process in which case <strong>it will trigger <code>RejoinAsNewlookup</code></strong>.
Based on number of final blocks missed over period of recovery, Rejoin will be either based out of incremental db or it will continue syncing the missing blocks from lookup. For details refer <a href="join-rejoin.md###`Lookup::RejoinAsNewlookup`">Rejoin</a></li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="lookup-node-recovery"></a><a href="#lookup-node-recovery" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Lookup Node Recovery</h3>
<ol>
<li>Kills Zilliqa process, and suspend the new process re-launching.</li>
<li>Testnet script downloads Persistence Storage.</li>
<li>Resumes to launch Zilliqa process with <code>syncType 5</code> i.e. <code>RECOVERY_ALL_SYNC</code></li>
<li>Zilliqa process retrieves Persistence Storage downloaded earlier by testnet script in step (2).</li>
<li>syncType is not <code>NO_SYNC</code>. So it blocks some messages that will be received as a healthy node.</li>
<li>Invokes <code>WakeupAtTxEpoch</code> which will start with state on <code>WAITING_FINALBLOCK</code>.</li>
</ol>
<p>There are two possibilities hereafter:</p>
<ul>
<li>Receives next final block and joined back.</li>
<li>We missed new final block during recovery process in which case <strong>it will trigger <code>RejoinAsLookup</code></strong>. Refer <a href="join-rejoin.md###`Lookup::RejoinAsLookup`">Rejoin</a></li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="view-change"></a><a href="#view-change" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>View Change</h2>
<p>This document describes the view change process in Zilliqa. For automation of viewchange tests, please refer to this <a href="https://github.com/Zilliqa/testnet/blob/master/vc_test/VCTESTS.md">link</a></p>
<!-- TOC depthTo:2 -->
<ul>
<li><a href="#description">Description</a></li>
<li><a href="#usage">Usage</a></li>
<li><a href="#terminology">Terminology</a></li>
<li><a href="#trigger-conditions">Trigger conditions</a></li>
<li><a href="#setup">Setup</a></li>
<li><a href="#procedure">Procedure</a></li>
<li><a href="#test-scenario-setup">Test scenario setup</a></li>
<li><a href="#general-test-scenario">General test scenario</a></li>
<li><a href="#special-test-scenario">Special test scenario</a></li>
<li><a href="#test-macro">Test macro</a></li>
<li><a href="#known-issues">Known issues</a></li>
</ul>
<!-- /TOC -->
<h3><a class="anchor" aria-hidden="true" id="description-1"></a><a href="#description-1" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Description</h3>
<p>This version of view change supports random candidate leader selection and re-selection of the candidate leader if it is faulty. It also fixes the issue where the wrong ds leader is ejected to the back of the queue, which is the result of a previous hotfix that fixes view change issue after random DS leader election.</p>
<p>To conduct view change, the general steps are as follows:</p>
<ol>
<li>A stall in consensus must have happened</li>
<li>Network enters into view change state</li>
<li>Candidate leader leads the view change consensus using PBFT</li>
<li>Backups validate the announcement</li>
<li>View change consensus is reached</li>
<li>Re-run the stalled consensus</li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="usage"></a><a href="#usage" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Usage</h3>
<p>Allows election of a new leader when the network cannot reach an agreement of the next state and stalled the consensus process</p>
<h3><a class="anchor" aria-hidden="true" id="terminology-1"></a><a href="#terminology-1" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Terminology</h3>
<ol>
<li>Candidate leader: Known as the proposed leader, the candidate leader will lead view change consensus round</li>
<li>Faulty leader(s): The current or previous DS leader(s) that is deemed to be faulty</li>
<li>Ejection: Eject the faulty leader(s) to the back of the ds committee. It will then be fully kicked out of the DS committee after the next DS consensus</li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="trigger-conditions"></a><a href="#trigger-conditions" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Trigger conditions</h3>
<ol>
<li>Node entered “RunConsensusOnDSBlock” but DS block consensus did not complete within the time stipulated</li>
<li>Node entered “RunConsensusOnFinalBlock” but final consensus did not complete within the time stipulated</li>
<li>Node entered “RunConsensusOnViewChange” but view change consensus did not complete within the time stipulated</li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="setup"></a><a href="#setup" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Setup</h3>
<ol>
<li><code>[VC Block header]</code> Removal of candidate leader index as the index will be adjusted after view change and will be obsolete</li>
<li><code>[VC Block header]</code> Addition of <code>vector&lt;pair&lt;PubKey, Peer&gt;&gt;</code> for tracking all the faulty leaders</li>
<li><code>[Macro]</code> Add the related test scenario macro. Refer to test macros section.</li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="procedure"></a><a href="#procedure" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Procedure</h3>
<ol>
<li><p>Consensus stalled during DS consensus or Final block consensus</p></li>
<li><p>View change condition variable is triggered</p></li>
<li><p>Enter view change consensus</p></li>
<li><p><code>[Precheck]</code> Enter the precheck phase. DS nodes contact lookup to ask for new blocks</p></li>
<li><p><code>[Precheck]</code> If no new blocks (DS and FB) is obtained, proceeds to do view change</p></li>
<li><p><code>[Precheck]</code> Else, rejoin as a DS node</p></li>
<li><p>All nodes calculate the new candidate leader index using <code>CalculateNewLeaderIndex()</code></p></li>
<li><p><code>CalculateNewLeaderIndex()</code> calculates candidate leader index using</p>
<pre><code class="hljs css language-text">H(finalblock or vc block hash, vc counter) % size (or num of DS guard)

If a previous vc block (for current consensus) exists, use vc block hash. Else use final block hash. If new candidate leader index is current faulty leader, re-calculate using
H(H(finalblock or vc block hash, vc counter)) repeatedly till an index is not the current faulty leader.
</code></pre></li>
<li><p>Candidate leader leads the consensus round</p></li>
<li><p>Backups validate leader announcement</p></li>
<li><p>View change consensus completed/stalled
a. If stalled, wait for timeout and re-run view change consensus with a new candidate leader</p></li>
<li><p>Remove faulty leaders (found in Faulty leader vector) from DS Committee</p></li>
<li><p>Add faulty leaders (found in Faulty leader vector) to the back DS Committee (if not in guard mode)</p></li>
<li><p>Recalculate <code>m_consensusMyID</code> by searching for own node inside the DS committee</p></li>
<li><p>Set new DS <code>m_consensusLeaderID</code></p></li>
<li><p>Store VC block to persistent storage</p></li>
<li><p>If stalled consensus is at final block consensus, send the VC block to the lookup and shard nodes. Lookups and shard nodes update the ds composition respectively</p></li>
<li><p>If stalled consensus is at DS block consensus, hold and collect VC block(s) to the lookup and shard nodes.</p></li>
<li><p>Re-run stalled consensus (DS block or final block consensus). If re-run is at final block consensus, gas limit will be adjusted using exponential backoff algorithm.</p></li>
<li><p>Consensus completed</p></li>
<li><p>If DS block consensus, concatenate the DS block with VC block(s) and send to lookup and shard nodes</p></li>
<li><p>Lookup and shard nodes will process VC block(s) linearly followed by DS block</p></li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="test-scenario-setup"></a><a href="#test-scenario-setup" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Test scenario setup</h3>
<p>A total of 6 general view change tests is built into the codebase as macro. To perform the test,</p>
<ol>
<li><p>Remove the build folder</p></li>
<li><p>For a single test scenario</p>
<pre><code class="hljs css language-bash">./build.sh vc&lt;1-6&gt;
</code></pre></li>
<li><p>For multiple test scenario</p>
<pre><code class="hljs css language-bash">./build.sh vc&lt;1-6&gt; vc&lt;1-6&gt;
</code></pre></li>
<li><p>Build twice as the <code>ccache</code> may be hindering the macros</p></li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="general-test-scenario"></a><a href="#general-test-scenario" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>General test scenario</h3>
<h4><a class="anchor" aria-hidden="true" id="single-failure"></a><a href="#single-failure" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Single failure</h4>
<ol>
<li><code>vc1</code> - DS leader stalled at DS block consensus</li>
<li><code>vc3</code> - DS leader stalled at Final block consensus</li>
</ol>
<h4><a class="anchor" aria-hidden="true" id="multiple-failures-after-view-change-is-completed"></a><a href="#multiple-failures-after-view-change-is-completed" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Multiple failures (after view change is completed)</h4>
<ol>
<li><code>vc2</code> - DS leader stalls at DS block consensus and 2 candidate leaders stall at DS block consensus</li>
<li><code>vc4</code> - DS leader stalls at Final block consensus and 2 candidate leaders stall at Final block consensus</li>
</ol>
<h4><a class="anchor" aria-hidden="true" id="multiple-failures-with-view-change-consensus-failure"></a><a href="#multiple-failures-with-view-change-consensus-failure" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Multiple failures (with view change consensus failure)</h4>
<ol>
<li><code>vc1 vc5</code> - DS leader stalls at DS block consensus and candidate leaders stall at View Change consensus</li>
<li><code>vc3 vc5</code> - DS leader stalls at Final block consensus and candidate leader stall at View Change consensus</li>
<li><code>vc1 vc6</code> - DS leader stalls at DS block consensus and 2 candidate leaders stall at View Change consensus</li>
<li><code>vc3 vc6</code> - DS leader stalls at Final block consensus and 2 candidate leaders stall at View Change consensus</li>
</ol>
<h4><a class="anchor" aria-hidden="true" id="vc-pre-check-failed"></a><a href="#vc-pre-check-failed" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>VC Pre-check failed</h4>
<ol>
<li><code>vc7</code> - When a DS backup is lagged (ds epoch) and the whole network did not enter into view change, check whether the node will rejoin as DS or not. Node with <code>consensusMyID</code> 3 will stall for 45s and enter view change to simulate node lagging behind.</li>
<li><code>vc8</code> - When a DS backup is lagged (tx epoch) and the whole network did not enter into view change, check whether the node will rejoin as DS or not. Node with <code>consensusMyID</code> 3 will stall for 45s and enter view change to simulate node lagging behind.</li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="special-test-scenario"></a><a href="#special-test-scenario" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Special test scenario</h3>
<p>Test plan for merging DS Microblock into FinalBlock consensus</p>
<ol>
<li><p>Objective: Check fetching missing txn
Scenario : DS leader has some txn that one of the backups doesn't have
Adoption : Letting one of the backups accept fewer txns from lookup comparing to the others</p></li>
<li><p>Objective: Check View Change due to dsblock check failure within FinalBlock consensus
Scenario : DS leader has some txn that all of backups don't have
Adoption : Letting all of the backups accept fewer txns from lookup comparing to the leader</p></li>
<li><p>Objective: Check fetching missing microblock
Scenario : DS leader has more microblock received than one of the backups
Adoption : Letting one of the backups refuse some Microblock submission</p></li>
<li><p>Objective: Check View Change after fetching missing microblock
Scenario : DS leader has more microblock received than all of the backups
Adoption : Letting all of the backups refuse some Microblock submission</p></li>
<li><p>Objective: Check View Change due to TxBlock check failure within FinalBlock consensus
Scenario : DS leader composed invalid TxBlock
Adoption : Done by composing wrong state root hash</p></li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="test-macro"></a><a href="#test-macro" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Test macro</h3>
<ol>
<li><code>vc1</code> - stall at the start of ds consensus for 1 time</li>
<li><code>vc2</code> - stall at the start of ds consensus for 3 times</li>
<li><code>vc3</code> - stall at the start of final consensus for 1 time</li>
<li><code>vc4</code> - stall at the start of final consensus for 3 times</li>
<li><code>vc5</code> - stall at the start of vc consensus for 1 time</li>
<li><code>vc6</code> - stall at the start of vc consensus for 2 times</li>
<li><code>vc7</code> - Node with <code>consensusMyID 3</code> will stall for 45s and enter view change to simulate node lagging behind at DS block consensus. Node will precheck and rejoin as DS. Network will not undergo view change</li>
<li><code>vc8</code> - Node with <code>consensusMyID 3</code> will stall for 45s and enter view change to simulate node lagging behind at Final block consensus. Node will precheck and rejoin as DS. Network will not undergo view change</li>
<li><code>dm1</code> - letting one of the backups accept fewer txns from lookup comparing to the others</li>
<li><code>dm2</code> - letting all of the backups accept fewer txns from lookup comparing to the leader</li>
<li><code>dm3</code> - letting one of the backups refuse some Microblock submission</li>
<li><code>dm4</code> - letting all of the backups refuse some Microblock submission</li>
<li><code>dm5</code> - compose the wrong TxBlock, done by composing wrong state root hash in the TxBlock</li>
<li><code>dm6</code> - compose the wrong DSMicroBlock, done by composing wrong tranhashes in the DSMicroBlock</li>
<li><code>dm7</code> - letting the ds leader accept fewer txns from lookup comparing to the others</li>
<li><code>dm8</code> - letting the ds leader and half of the ds committee members accept fewer txns from lookup comparing to the others</li>
<li><code>dm9</code> - letting the ds leader and half of the ds committee members refuse some MicroBlock submission</li>
</ol>
<h3><a class="anchor" aria-hidden="true" id="known-issues"></a><a href="#known-issues" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Known issues</h3>
<ol>
<li><code>VC7</code> and <code>VC8</code> require uploading of persistent storage from lookup. However, this process is not automated. Hence, these two tests will require manual intervention.
<ul>
<li>Run test</li>
<li>Upload lookup incremental DB at epoch 5</li>
<li>Observe DS node with <code>consensusMyID</code> 3 goes into view change and pre-checking</li>
<li>Check for invocation of <code>RejoinAsDS()</code> and <code>FinishRejoinAsDS()</code></li>
</ul></li>
<li><code>DM3</code> not working due to constant settings. This is not an issue</li>
<li><code>DM8</code> and <code>DM9</code> cannot be accurately validated using script</li>
</ol>
<h2><a class="anchor" aria-hidden="true" id="transaction-backup"></a><a href="#transaction-backup" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Transaction Backup</h2>
<h2><a class="anchor" aria-hidden="true" id="diagnostic-data"></a><a href="#diagnostic-data" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Diagnostic Data</h2>
<p>We store in LevelDB a limited amount of some operational data about the network that is intended for use when diagnosing any issues with the mainnet.</p>
<p>Globally, the amount of data stored is controlled by the constant <code>MAX_ENTRIES_FOR_DIAGNOSTIC_DATA</code>, which is usually set to either 25 or 50.</p>
<p>This is the current data stored for diagnostic purposes:</p>
<table>
<thead>
<tr><th>LevelDB location</th><th>Data stored</th><th>Storage timing</th><th>Tool for data extraction</th></tr>
</thead>
<tbody>
<tr><td>persistence/diagnosticNodes</td><td>DS and shard peers</td><td>Every vacuous epoch</td><td>getnetworkhistory</td></tr>
<tr><td>persistence/diagnosticCoinb</td><td>Coinbase values and distribution</td><td>Every DS block</td><td>getrewardhistory</td></tr>
</tbody>
</table>
<p>To use the diagnostic tools:</p>
<ol>
<li>Make sure there is a <code>persistence</code> subfolder in your current directory.</li>
<li>Make sure <code>persistence/diagnosticNodes</code> <code>persistence/diagnosticCoinb</code> contains the data you want to extract.</li>
<li>Run <code>getnetworkhistory &lt;name of output CSV file&gt;</code> or <code>getrewardhistory &lt;name of output CSV file&gt;</code>.</li>
<li>Output CSV file will appear in the current directory. Use Excel or LibreOffice Calc to open it.</li>
</ol>
<h2><a class="anchor" aria-hidden="true" id="internal-api"></a><a href="#internal-api" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Internal API</h2>
<p>This API server runs on port 4301 by default on a node locally (i.e., cannot be accessed from outside).</p>
<h3><a class="anchor" aria-hidden="true" id="available-methods"></a><a href="#available-methods" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Available Methods</h3>
<ul>
<li><strong><code>AddToBlacklistExclusion</code></strong>: Can be used to add an API to the blacklist exclusion list (or whitelist).</li>
<li><strong><code>RemoveFromBlacklistExclusion</code></strong>: Can be used to remove an API from the blacklist exclustion list.</li>
<li><strong><code>GetNodeState</code></strong>: Used to get the state of the node, e.g., POW, COMMIT_DONE etc.</li>
<li><strong><code>GetEpochFin</code></strong>: Tells the epoch number for the lookup for which the microblocks and txns have been received.</li>
<li><strong><code>GetDSCommittee</code></strong>: Returns the list of IPs and PubKeys of the current DS Committee.</li>
<li><strong><code>IsTxnInMemPool</code></strong>: Used to query local mempool of the nodes. Can tell, given a particular txnhash, if it is in mempool and why (e.g., nonce too high or gas price low).</li>
</ul>
</span></div></article></div><div class="docs-prevnext"><a class="docs-prev button" href="/dev-portal/docs/en/core-mining"><span class="arrow-prev">← </span><span>Mining</span></a><a class="docs-next button" href="/dev-portal/docs/en/core-tools"><span>Tools</span><span class="arrow-next"> →</span></a></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#guard-mode">Guard Mode</a><ul class="toc-headings"><li><a href="#description">Description</a></li><li><a href="#terminology">Terminology</a></li><li><a href="#operation">Operation</a></li><li><a href="#design-of-ds-guard-and-non-ds-guard-nodes">Design of DS guard and non-DS guard nodes</a></li><li><a href="#changing-network-information-of-ds-guard-node">Changing network information of DS guard node</a></li><li><a href="#design-of-shard-guard-and-non-shard-guard-nodes">Design of shard guard and non-shard guard nodes</a></li><li><a href="#running-in-local-test-mode">Running in local test mode</a></li><li><a href="#test-scenarios">Test scenarios</a></li><li><a href="#validating-the-results-via-sampling">Validating the results via sampling</a></li><li><a href="#future-todos">Future todos</a></li></ul></li><li><a href="#rejoin-mechanism">Rejoin Mechanism</a><ul class="toc-headings"><li><a href="#new-node-joining---existing-shard-node-joiningminer-node-was-relaunchedrestarted-via-launcher-script">New node joining  / Existing shard node joining(Miner node was relaunched/restarted via launcher script)</a></li><li><a href="#shard-node---daemon-starts-the-killed-zilliqa-process-applicable-only-for-zilliqa-nodes">Shard node - Daemon starts the killed zilliqa process (applicable only for zilliqa nodes)</a></li><li><a href="#existing-ds-node-joining--ds-node-was-relaunchedrestarted-via-launcher-script">Existing DS node joining ( DS node was relaunched/restarted via launcher script)</a></li><li><a href="#ds-node---when-vc-precheck-fails">DS node - when VC Precheck fails</a></li><li><a href="#ds-node---daemon-starts-the-killed-zilliqa-process-applicable-only-for-zilliqa-nodes">DS node - Daemon starts the killed zilliqa process (applicable only for zilliqa nodes)</a></li><li><a href="#new-seed-node-joining">New Seed Node joining</a></li><li><a href="#seed-node-rejoining-also-applicable-for-newlookup--level2lookup-nodes">Seed Node Rejoining (Also applicable for newlookup / level2lookup nodes)</a></li><li><a href="#lookup-node-rejoining">Lookup Node Rejoining</a></li></ul></li><li><a href="#recovery-mechanism">Recovery Mechanism</a><ul class="toc-headings"><li><a href="#ds-guard-node-recovery">DS Guard Node Recovery</a></li><li><a href="#ds-guard-node-podinstance-deletion">DS Guard Node Pod/Instance Deletion</a></li><li><a href="#shard-guard-node-recovery">Shard Guard Node Recovery</a></li><li><a href="#shard-guard-node-podinstance-deletion">Shard Guard Node Pod/Instance Deletion</a></li><li><a href="#other-node-not-part-of-ds-committe-or-any-shard">Other Node (Not part of ds committe or any shard)</a></li><li><a href="#newlookup--level2lookup-node-recovery">NewLookup / Level2Lookup Node Recovery</a></li><li><a href="#lookup-node-recovery">Lookup Node Recovery</a></li></ul></li><li><a href="#view-change">View Change</a><ul class="toc-headings"><li><a href="#description-1">Description</a></li><li><a href="#usage">Usage</a></li><li><a href="#terminology-1">Terminology</a></li><li><a href="#trigger-conditions">Trigger conditions</a></li><li><a href="#setup">Setup</a></li><li><a href="#procedure">Procedure</a></li><li><a href="#test-scenario-setup">Test scenario setup</a></li><li><a href="#general-test-scenario">General test scenario</a></li><li><a href="#special-test-scenario">Special test scenario</a></li><li><a href="#test-macro">Test macro</a></li><li><a href="#known-issues">Known issues</a></li></ul></li><li><a href="#transaction-backup">Transaction Backup</a></li><li><a href="#diagnostic-data">Diagnostic Data</a></li><li><a href="#internal-api">Internal API</a><ul class="toc-headings"><li><a href="#available-methods">Available Methods</a></li></ul></li></ul></nav></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/dev-portal/" class="nav-home"><img src="/dev-portal/img/zilliqa-logo_1zilliqa-logo.png" alt="Zilliqa Developer Portal" width="66" height="70"/></a><div><h5>Links</h5><a href="https://www.github.com/Zilliqa" target="_blank" rel="noreferrer noopener">GitHub</a><a href="https://blog.zilliqa.com/" target="_blank" rel="noreferrer noopener">Medium</a><a href="https://twitter.com/zilliqa" target="_blank" rel="noreferrer noopener">Twitter</a><a href="https://discord.gg/XMRE9tt" target="_blank" rel="noreferrer noopener">Discord</a><a href="https://www.youtube.com/channel/UCvinnFbf0u71cajoxKcfZIQ" target="_blank" rel="noreferrer noopener">YouTube</a></div></section><section class="copyright">Copyright © 2020 Zilliqa Research Pte. Ltd.</section></footer></div></body></html>